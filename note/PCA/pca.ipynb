{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主成分分析（Principal Component Analysis，PCA）是一种多变量统计方法，它是最常用的降维方法之一，通过正交变换将一组可能存在相关性的变量数据转换为一组线性不相关的变量，转换后的变量被称为主成分。\n",
    "\n",
    "可以使用两种方法进行 PCA，分别是特征分解或奇异值分解（SVD）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先从协方差说起"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "协方差$$cov(X,Y)=\\frac{\\sum_{i=1}^n{(X_i-\\bar{X})(Y_i-\\bar{Y})}}{n-1}$$\n",
    "\n",
    "协方差其意义：\n",
    "度量各个维度偏离其均值的程度。协方差的值如果为正值，则说明两者是正相关的(从协方差可以引出“相关系数”的定义)，结果为负值就说明负相关的，如果为0，也是就是统计上说的“相互独立”。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "协方差矩阵：  \n",
    "$$C = \\begin{pmatrix}\n",
    "    cov(x,x) &cov(x,y)  & cov(x,z) \\\\\n",
    "   cov(y,x)  & cov(y,y) &  cov(y,z) \\\\\n",
    "   cov(z,x)  & cov(z,y) &cov(z,z)   \\\\\n",
    "\\end{pmatrix}\\qquad$$  \n",
    "从协方差矩阵上，可以得到变量之间两两的相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mpld3\n",
    "#%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:51.830870Z",
     "start_time": "2019-12-16T12:37:51.604096Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#设置一下np的输出格式\n",
    "np.set_printoptions(threshold=100,precision= 4,suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:52.323145Z",
     "start_time": "2019-12-16T12:37:52.301233Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算以下数据的协方差矩阵\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "data = np.random.uniform(1,10,(10,2))\n",
    "data[:,1:] = 0.5*data[:,0:1]+np.random.uniform(-2,2,(10,1))\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:52.323145Z",
     "start_time": "2019-12-16T12:37:52.301233Z"
    }
   },
   "source": [
    "必须去中心化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:54.514285Z",
     "start_time": "2019-12-16T12:37:54.508335Z"
    }
   },
   "outputs": [],
   "source": [
    "data_norm = data-data.mean(axis = 0)\n",
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:54.514285Z",
     "start_time": "2019-12-16T12:37:54.508335Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data_norm[:,0]\n",
    "Y = data_norm[:,1]\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:55.189482Z",
     "start_time": "2019-12-16T12:37:55.181529Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义一个函数，输入X，Y能得到X，Y之间的协方差\n",
    "def getcov(X,Y):\n",
    "\n",
    "    covxy = ((X-X.mean())*(Y-Y.mean())).sum()/(len(X)-1)\n",
    "\n",
    "    return covxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:56.496016Z",
     "start_time": "2019-12-16T12:37:56.489031Z"
    }
   },
   "outputs": [],
   "source": [
    "getcov(X,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:56.496016Z",
     "start_time": "2019-12-16T12:37:56.489031Z"
    }
   },
   "source": [
    "numpy自带了协方差矩阵的计算方法，验证一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:57.545204Z",
     "start_time": "2019-12-16T12:37:57.476361Z"
    }
   },
   "outputs": [],
   "source": [
    "C = np.cov(data_norm.T)\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:57.545204Z",
     "start_time": "2019-12-16T12:37:57.476361Z"
    }
   },
   "source": [
    "# 计算协方差矩阵的特征向量和特征值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由矩阵特征值特征向量的定义：\n",
    "$$Cv=\\lambda v$$\n",
    "其中，$λ$是特征向量$v$对应的特征值，一个矩阵的一组特征向量是一组正交向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征值分解矩阵\n",
    "\n",
    "对于矩阵$C$，有一组特征向量$V$，将这组向量进行正交化单位化，就能得到一组正交单位向量。特征值分解，就是将矩阵$C$分解为如下式：\n",
    "\n",
    "$$C=Q\\Sigma Q^{-1}$$\n",
    "\n",
    "其中，$Q$是矩阵$C$的特征向量组成的矩阵，$\\Sigma$则是一个对角阵，对角线上的元素就是特征值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:37:59.454098Z",
     "start_time": "2019-12-16T12:37:59.425178Z"
    }
   },
   "outputs": [],
   "source": [
    "#计算特征值和特征向量\n",
    "vals, vecs = np.linalg.eig(C)\n",
    "#重新排序，从大到小\n",
    "vecs = vecs[:,np.argsort(-vals)]\n",
    "vals = vals[np.argsort(-vals)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:38:00.160511Z",
     "start_time": "2019-12-16T12:38:00.153529Z"
    }
   },
   "outputs": [],
   "source": [
    "#第一个特征值对应的特征向量\n",
    "vals[0],vecs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:38:00.160511Z",
     "start_time": "2019-12-16T12:38:00.153529Z"
    }
   },
   "outputs": [],
   "source": [
    "#第二个特征值对应的特征向量\n",
    "vals[1],vecs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:38:00.710008Z",
     "start_time": "2019-12-16T12:38:00.702029Z"
    }
   },
   "source": [
    "这时候，相当于已经在数据中定义了两个轴，第一个轴的方向是第一个特征向量$v_1$，第二个轴的方向是第二个特征向量$v_2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:38:06.555409Z",
     "start_time": "2019-12-16T12:38:06.365913Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#设置图大小\n",
    "size = 15\n",
    "\n",
    "plt.figure(1,(8,8))\n",
    "\n",
    "plt.scatter(data[:,0],data[:,1],label='origin data')\n",
    "\n",
    "i=0\n",
    "ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "ev = (ev+data.mean(0))\n",
    "plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "i=1\n",
    "ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "ev = (ev+data.mean(0))\n",
    "plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "#plt.plot(vecs[:,1]*-10,vecs[:,1]*10)\n",
    "\n",
    "#画一下x轴y轴\n",
    "plt.plot([-size,size],[0,0],c='black')\n",
    "plt.plot([0,0],[-size,size],c='black')\n",
    "plt.xlim(-size,size)\n",
    "plt.ylim(-size,size)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T12:38:06.555409Z",
     "start_time": "2019-12-16T12:38:06.365913Z"
    }
   },
   "source": [
    "如果用PCA把$m$个维度的数据降维成$k$个维度，即只用前$k$个主成分来表示，那么数据在主成分上的投影坐标是\n",
    "$$Y_{n*k} = X_{n*m}Q_{m*k}$$\n",
    "$Q$为特征向量组成的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:49:29.765196Z",
     "start_time": "2019-09-28T07:49:29.758212Z"
    }
   },
   "outputs": [],
   "source": [
    "#数据在主成分1上的投影坐标是Y\n",
    "k=1\n",
    "Q = vecs[:,:k]\n",
    "Y = np.matmul(data_norm,Q)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:49:29.765196Z",
     "start_time": "2019-09-28T07:49:29.758212Z"
    }
   },
   "source": [
    "这个时候我们相当于只需要存储**前k个主成分的特征向量$Q_{m*k}$**和**数据在前k个主成分上的投影坐标$Y_{n*k}$**，就可以还原数据\n",
    "$$Y_{n*k}{Q_{m*k}}^T=X_{n*m}$$\n",
    "其中，由于$Q$已经正交化，${Q_{m*k}}^T{Q_{m*k}}=I_{k*k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:49:37.877532Z",
     "start_time": "2019-09-28T07:49:37.871519Z"
    }
   },
   "outputs": [],
   "source": [
    "#得到去中心化的还原数据\n",
    "np.matmul(Y,Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:49:37.877532Z",
     "start_time": "2019-09-28T07:49:37.871519Z"
    }
   },
   "outputs": [],
   "source": [
    "#加上均值，还原数据\n",
    "data_ = np.matmul(Y,Q.T)+data.mean(0)\n",
    "data_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:49:49.490889Z",
     "start_time": "2019-09-28T07:49:49.482910Z"
    }
   },
   "source": [
    "# 降维重构的数据与原数据对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用我们刚刚的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:37:39.427597Z",
     "start_time": "2019-09-28T07:37:39.248080Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#设置图大小\n",
    "size = 10\n",
    "\n",
    "plt.figure(1,(8,8))\n",
    "\n",
    "plt.scatter(data[:,0],data[:,1],label='origin data')\n",
    "\n",
    "plt.scatter(data_[:,0],data_[:,1],label='restructured data')\n",
    "\n",
    "i=0\n",
    "ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "ev = (ev+data.mean(0))\n",
    "plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "i=1\n",
    "ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "ev = (ev+data.mean(0))\n",
    "plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "#plt.plot(vecs[:,1]*-10,vecs[:,1]*10)\n",
    "\n",
    "#画一下x轴y轴\n",
    "plt.plot([-size,size],[0,0],c='black')\n",
    "plt.plot([0,0],[-size,size],c='black')\n",
    "plt.xlim(-size,size)\n",
    "plt.ylim(-size,size)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:37:39.427597Z",
     "start_time": "2019-09-28T07:37:39.248080Z"
    }
   },
   "source": [
    "## 用sklearn的PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:01:58.926896Z",
     "start_time": "2019-09-28T07:01:58.656028Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2) \n",
    "pca.fit(data)\n",
    "Y = pca.fit_transform(data)\n",
    "vecs = pca.components_.T\n",
    "data_ = np.dot(Y[:,:1],vecs[:,:1].T)+data.mean(0)\n",
    "\n",
    "\n",
    "#设置图大小\n",
    "size = 10\n",
    "\n",
    "plt.figure(1,(8,8))\n",
    "\n",
    "plt.scatter(data[:,0],data[:,1],label='origin data')\n",
    "\n",
    "plt.scatter(data_[:,0],data_[:,1],label='restructured data')\n",
    "\n",
    "i=0\n",
    "ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "ev = (ev+data.mean(0))\n",
    "plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "i=1\n",
    "ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "ev = (ev+data.mean(0))\n",
    "plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "#plt.plot(vecs[:,1]*-10,vecs[:,1]*10)\n",
    "\n",
    "#画一下x轴y轴\n",
    "plt.plot([-size,size],[0,0],c='black')\n",
    "plt.plot([0,0],[-size,size],c='black')\n",
    "plt.xlim(-size,size)\n",
    "plt.ylim(-size,size)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:01:58.926896Z",
     "start_time": "2019-09-28T07:01:58.656028Z"
    }
   },
   "source": [
    "## 用SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:51:59.367754Z",
     "start_time": "2019-09-28T07:51:59.361775Z"
    }
   },
   "outputs": [],
   "source": [
    "#用SVD主要是想用SVD求出主成分的方向向量\n",
    "U,vals,V = np.linalg.svd(data_norm)\n",
    "vecs = V.T\n",
    "\n",
    "#数据在主成分1上的投影坐标是Y\n",
    "Y = np.matmul(data_norm,vecs[:,:1])\n",
    "#得到去中心化的还原数据\n",
    "data_ = np.matmul(Y,vecs[:,:1].T)+data.mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:52:01.356474Z",
     "start_time": "2019-09-28T07:52:01.209832Z"
    }
   },
   "outputs": [],
   "source": [
    "#画图\n",
    "import matplotlib.pyplot as plt\n",
    "#设置图大小\n",
    "size = 10\n",
    "\n",
    "plt.figure(1,(8,8))\n",
    "\n",
    "plt.scatter(data[:,0],data[:,1],label='origin data')\n",
    "\n",
    "plt.scatter(data_[:,0],data_[:,1],label='restructured data')\n",
    "\n",
    "#绘制主成分的向量\n",
    "i=0\n",
    "ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "ev = (ev+data.mean(0))\n",
    "plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "i=1\n",
    "ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "ev = (ev+data.mean(0))\n",
    "plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "#plt.plot(vecs[:,1]*-10,vecs[:,1]*10)\n",
    "\n",
    "#画一下x轴y轴\n",
    "plt.plot([-size,size],[0,0],c='black')\n",
    "plt.plot([0,0],[-size,size],c='black')\n",
    "plt.xlim(-size,size)\n",
    "plt.ylim(-size,size)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:52:01.356474Z",
     "start_time": "2019-09-28T07:52:01.209832Z"
    }
   },
   "source": [
    "# 三维数据的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:52:07.468091Z",
     "start_time": "2019-09-28T07:52:07.461115Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算以下数据的协方差矩阵\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "data = np.random.uniform(-10,10,(20,3))\n",
    "data[:,1:] = 0.5*data[:,0:1]+np.random.uniform(-2,2,(20,1))\n",
    "data[:,2:] = 0.5*data[:,0:1]+np.random.uniform(-3,3,(20,1))\n",
    "\n",
    "\n",
    "data_normal = data-data.mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:52:07.955787Z",
     "start_time": "2019-09-28T07:52:07.936843Z"
    }
   },
   "outputs": [],
   "source": [
    "C = np.cov(data_normal.T)\n",
    "\n",
    "#计算特征值和特征向量\n",
    "vals, vecs = np.linalg.eig(C)\n",
    "#重新排序，从大到小\n",
    "vecs = vecs[:,np.argsort(-vals)]\n",
    "vals = vals[np.argsort(-vals)]\n",
    "\n",
    "vals,vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:52:07.955787Z",
     "start_time": "2019-09-28T07:52:07.936843Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, mpld3\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "X = data[:,0]\n",
    "Y = data[:,1]\n",
    "Z = data[:,2]\n",
    "\n",
    "for i in range(45,60):\n",
    "    #让图转起来\n",
    "    import IPython\n",
    "    IPython.display.clear_output(wait=True)\n",
    "\n",
    "    fig = plt.figure(1,(6,4),dpi = 250)\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    plt.cla()\n",
    "    #绘制散点\n",
    "    ax.scatter(X,Y,Z,s=5)\n",
    "\n",
    "    #绘制xyz轴\n",
    "    ax.plot([0,0],[0,0],[-10,10],c = 'black',linewidth = 0.8)\n",
    "    ax.plot([0,0],[-10,10],[0,0],c = 'black',linewidth = 0.8)\n",
    "    ax.plot([-10,10],[0,0],[0,0],c = 'black',linewidth = 0.8)\n",
    "    \n",
    "    \n",
    "    ax.view_init(azim=i)\n",
    "    plt.xlim(-X.max(), X.max())\n",
    "    plt.ylim(-Y.max(), Y.max())\n",
    "    ax.set_zlim(-Z.max(),Z.max())\n",
    "    plt.title('PCA')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:52:14.218084Z",
     "start_time": "2019-09-28T07:52:08.497344Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#数据在主成分1上的投影坐标是\n",
    "zcf = np.matmul(data_normal,vecs[:,:2])\n",
    "data_ = np.matmul(zcf,vecs[:,:2].T)+data.mean(0)\n",
    "data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:52:22.069104Z",
     "start_time": "2019-09-28T07:52:16.635580Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, mpld3\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "X = data[:,0]\n",
    "Y = data[:,1]\n",
    "Z = data[:,2]\n",
    "\n",
    "X_ = data_[:,0]\n",
    "Y_ = data_[:,1]\n",
    "Z_ = data_[:,2]\n",
    "\n",
    "for i in range(35,55):\n",
    "    #让图转起来\n",
    "    import IPython\n",
    "    IPython.display.clear_output(wait=True)\n",
    "\n",
    "    fig = plt.figure(1,(6,4),dpi = 250)\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    plt.cla()\n",
    "    #绘制散点\n",
    "    ax.scatter(X,Y,Z,s=5,label='origin data')\n",
    "    \n",
    "    ax.scatter(X_,Y_,Z_,s=5,label='restructured data')\n",
    "    ax.plot_trisurf(X_, Y_, Z_)\n",
    "    #绘制xyz轴\n",
    "    ax.plot([0,0],[0,0],[-10,10],c = 'black',linewidth = 0.8)\n",
    "    ax.plot([0,0],[-10,10],[0,0],c = 'black',linewidth = 0.8)\n",
    "    ax.plot([-10,10],[0,0],[0,0],c = 'black',linewidth = 0.8)\n",
    "    \n",
    "    \n",
    "    ax.view_init(azim=i)\n",
    "    plt.xlim(-X.max(), X.max())\n",
    "    plt.ylim(-Y.max(), Y.max())\n",
    "    ax.set_zlim(-Z.max(),Z.max())\n",
    "    plt.title('PCA')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这关奇异值什么事？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 奇异值分解  $Singular$ $Value$ $Decomposition$ $(SVD)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "奇异值分解是一个能适用于任意矩阵的一种分解的方法，对于任意矩阵A总是存在一个奇异值分解：\n",
    "\n",
    "$$A=U\\Sigma V^T$$\n",
    "\n",
    "假设A是一个$m*n$的矩阵，那么得到的$U$是一个$m*m$的方阵，$U$里面的正交向量被称为左奇异向量。  \n",
    "$Σ$是一个$m*n$的矩阵，$Σ$除了对角线其它元素都为0，对角线上的元素称为奇异值。  \n",
    "$V^T$是$V$的转置矩阵，是一个$n*n$的矩阵，它里面的正交向量被称为右奇异值向量。  \n",
    "而且一般来讲，我们会将$Σ$上的值按从大到小的顺序排列。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD分解矩阵A的步骤：\n",
    "\n",
    "1) 求的$AA^T$特征值和特征向量，用单位化的特征向量构成$U$。  \n",
    "2) 求的$A^TA$特征值和特征向量，用单位化的特征向量构成$V$。  \n",
    "3) 将$AA^T$或者$A^TA$的特征值求平方根，然后构成$Σ$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们自己实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T08:16:56.686459Z",
     "start_time": "2019-09-28T08:16:56.676489Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#求U\n",
    "valsU,U = np.linalg.eig(np.dot(data_normal,data_normal.T))\n",
    "#以特征值排序\n",
    "U = U[:,np.argsort(-valsU)]\n",
    "valsU = valsU[np.argsort(-valsU)]\n",
    "\n",
    "#求V\n",
    "valsV,V = np.linalg.eig(np.dot(data_normal.T,data_normal))\n",
    "#以特征值排序\n",
    "V = V[:,np.argsort(-valsV)]\n",
    "valsV = valsV[np.argsort(-valsV)]\n",
    "V = V.T\n",
    "\n",
    "#求对角阵\n",
    "vals = valsV**0.5\n",
    "U,vals,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T08:16:57.352678Z",
     "start_time": "2019-09-28T08:16:57.092379Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.real(U))\n",
    "plt.title('$U$')\n",
    "plt.show()\n",
    "\n",
    "m,n = data_normal.shape\n",
    "sigma = np.zeros((m,n))\n",
    "for i in range(min([m,n])):\n",
    "    sigma[i][i]=vals[i]\n",
    "\n",
    "plt.imshow(sigma)\n",
    "plt.title('$\\Sigma$')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.real(V))\n",
    "plt.title('$V$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T08:11:37.982706Z",
     "start_time": "2019-09-28T08:11:37.975726Z"
    }
   },
   "outputs": [],
   "source": [
    "#重构矩阵\n",
    "m,n = data_normal.shape\n",
    "sigma = np.zeros((m,n))\n",
    "for i in range(min([m,n])):\n",
    "    sigma[i][i]=vals[i]\n",
    "np.real(data_normal-np.dot(np.dot(U,sigma),V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np自带的svd实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T08:11:41.895241Z",
     "start_time": "2019-09-28T08:11:41.887267Z"
    }
   },
   "outputs": [],
   "source": [
    "U,vals,V = np.linalg.svd(data_normal)\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T08:11:42.347034Z",
     "start_time": "2019-09-28T08:11:42.339058Z"
    }
   },
   "outputs": [],
   "source": [
    "#重构矩阵\n",
    "m,n = data_normal.shape\n",
    "sigma = np.zeros((m,n))\n",
    "for i in range(min([m,n])):\n",
    "    sigma[i][i]=vals[i]\n",
    "data_normal-np.dot(np.dot(U,sigma),V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T08:16:28.054786Z",
     "start_time": "2019-09-28T08:16:27.796481Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.real(U))\n",
    "plt.title('U')\n",
    "plt.show()\n",
    "\n",
    "m,n = data_normal.shape\n",
    "sigma = np.zeros((m,n))\n",
    "for i in range(min([m,n])):\n",
    "    sigma[i][i]=vals[i]\n",
    "\n",
    "plt.imshow(sigma)\n",
    "plt.title('$\\Sigma$')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.real(V))\n",
    "plt.title('V')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:54:26.396308Z",
     "start_time": "2019-09-28T07:54:26.387303Z"
    }
   },
   "outputs": [],
   "source": [
    "#重构矩阵\n",
    "data_normal-np.dot(np.dot(U,sigma),V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到：用我们自己的方法做SVD的时候，结果和np的SVD结果不一样，这是因为U矩阵和V矩阵的正负问题，如果两者都取负，则抵消，结果也不变\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为什么要用SVD来做PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**很巧的是，SVD中的右奇异矩阵V，就是PCA的主成分**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在PCA降维中，我们需要找到样本协方差矩阵$C$的最大$k$个特征向量，然后用这最大的$k$个特征向量组成的矩阵来做低维投影降维。  \n",
    "可以看出，在这个过程中需要先求出协方差矩阵,当样本数多、样本特征数也多的时候，这个计算量还是很大的。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA的缺陷\n",
    "如果加入异常值，PCA的结果会发生什么变化？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T16:37:17.625251Z",
     "start_time": "2019-09-28T16:37:06.405287Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for i in range(0,720,10):\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    data = np.random.uniform(1,10,(20,2))\n",
    "    data[:,1:] = 0.5*data[:,0:1]+np.random.uniform(-2,2,(20,1))\n",
    "    \n",
    "\n",
    "\n",
    "    #如果我们在数据中加入异常值,定义一个角度放入异常值\n",
    "    i = 2*i/360*np.pi\n",
    "    data_outsider=[np.sin(i)*5*i/(2*np.pi),np.cos(i)*5*i/(2*np.pi)]\n",
    "    data = np.vstack((data,data_outsider))\n",
    "    \n",
    "    #去中心化\n",
    "    data_normal = data-data.mean(0)\n",
    "    X = data_normal[:,0]\n",
    "    Y = data_normal[:,1]\n",
    "    \n",
    "    #协方差矩阵\n",
    "    C = np.cov(data_normal.T)\n",
    "    \n",
    "    #计算特征值和特征向量\n",
    "    vals, vecs = np.linalg.eig(C)\n",
    "    \n",
    "    #重新排序，从大到小\n",
    "    vecs = vecs[:,np.argsort(-vals)]\n",
    "    vals = vals[np.argsort(-vals)]\n",
    "\n",
    "    #数据在主成分1上的投影坐标是\n",
    "    zcf1 = np.matmul(data_normal,vecs[:,0])\n",
    "    \n",
    "    #只用主成分1重构数据\n",
    "    data_ = np.matmul(zcf1.reshape(len(data),1),vecs[:,0].reshape(1,2))+data.mean(0)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    #设置图大小\n",
    "    size = 10\n",
    "    \n",
    "    #让图转起来，每次绘图都清空掉上一次绘制结果\n",
    "    import IPython\n",
    "    IPython.display.clear_output(wait=True)\n",
    "          \n",
    "    plt.figure(1,(8,8))\n",
    "\n",
    "    plt.scatter(data[:,0],data[:,1],label='origin data')\n",
    "    plt.scatter(data_[:,0],data_[:,1],label='restructured data')\n",
    "    plt.scatter(data[-1,0],data[-1,1],label='outsider')\n",
    "\n",
    "    i=0\n",
    "    \n",
    "    #绘制两个主成分的方向\n",
    "    ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "    ev = (ev+data.mean(0))\n",
    "    plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "    i=1\n",
    "    ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "    ev = (ev+data.mean(0))\n",
    "    plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "    \n",
    "    #绘制一下原始数据和重构数据的连线\n",
    "    for j in range(len(data)):\n",
    "        plt.plot([data[j,0],data_[j,0]],[data[j,1],data_[j,1]],c='black',linewidth = 0.5)\n",
    "        \n",
    "\n",
    "    #画一下x轴y轴\n",
    "    plt.plot([-size,size],[0,0],c='black')\n",
    "    plt.plot([0,0],[-size,size],c='black')\n",
    "    plt.xlim(-12.5,12.5)\n",
    "    plt.ylim(-12.5,12.5)\n",
    "    plt.title('result of PCA')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Principle Component Pursuit (SPCP)\n",
    " Stable Principle Component Pursuit (SPCP)是PCA的改进版本，它把问题变成：\n",
    "$$\\min_{L,S}{{ \\left\\Vert {L} \\right\\Vert }_*+\\lambda{ \\left\\Vert {S} \\right\\Vert }_1}$$\n",
    "$$s.t. M=L+S$$\n",
    "其中：\n",
    "$M$为原始矩阵  \n",
    "$L$为低秩矩阵，${ \\left\\Vert {L} \\right\\Vert }_*$为$L$矩阵核范数Nuclear Norm,为矩阵奇异值的和(用于表示低秩矩阵)  \n",
    "$S$为稀疏矩阵，${ \\left\\Vert {S} \\right\\Vert }_1$为矩阵L1范数（列模）:表示矩阵中非零元素的绝对值之和  \n",
    "$\\lambda=1/\\sqrt{max(m,n)}$  \n",
    "\n",
    "即，把原始矩阵分解为低秩矩阵与稀疏矩阵的和，这样子稀疏矩阵代表的就是矩阵的异常值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方便求解，引入拉格朗日乘数，把问题变成：\n",
    "$$\\min_{L,S}{{ \\left\\Vert {L} \\right\\Vert }_*+\\lambda{ \\left\\Vert {S} \\right\\Vert }_1}+\\mu{{ \\left\\Vert {N} \\right\\Vert }_F}$$\n",
    "其中:噪声矩阵$N=M-L-S$  \n",
    "建议的$\\mu$取值为$\\mu=\\sqrt{2max(m,n)}\\delta$，$\\delta={ \\left\\Vert {N} \\right\\Vert }_F$ ，这样子的取值足够大能够排除数据噪声，也足够小不会导致原始矩阵被过分缩小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用pytorch实现spcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T13:09:52.550062Z",
     "start_time": "2019-09-29T13:09:52.542090Z"
    }
   },
   "outputs": [],
   "source": [
    "m,n = data.shape\n",
    "m,n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T13:09:52.550062Z",
     "start_time": "2019-09-29T13:09:52.542090Z"
    }
   },
   "source": [
    "spcp的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T13:10:05.473494Z",
     "start_time": "2019-09-29T13:10:03.967562Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LR = 0.01\n",
    "\n",
    "L = torch.zeros([m,n],dtype=torch.float ,requires_grad=True)\n",
    "S = torch.zeros([m,n],dtype=torch.float ,requires_grad=True)\n",
    "M =  torch.tensor(data,dtype=torch.float ,requires_grad=False)\n",
    "\n",
    "lambda1 = 1/(max(m,n)**0.5)\n",
    "mu = 1/20 * torch.norm(M,p = 'nuc')\n",
    "\n",
    "optimizer = torch.optim.Adam([L,S],lr = LR,betas = (0.9,0.99))    \n",
    "\n",
    "t = 1\n",
    "steps = []\n",
    "losses = []\n",
    "N = M-L-S\n",
    "while torch.norm(N) > mu:\n",
    "    steps.append(t)\n",
    "    \n",
    "    N = M-L-S\n",
    "    loss = torch.norm(L,p = 'nuc')+lambda1 * torch.norm(S,p =1) + mu * torch.norm(N)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()      #初始化梯度\n",
    "    loss.backward()         #计算梯度\n",
    "    optimizer.step()   \n",
    "    '''\n",
    "    if t%10 == 0:\n",
    "        import IPython\n",
    "        IPython.display.clear_output(wait=True)\n",
    "\n",
    "        plt.plot(steps,losses,label = 'loss')\n",
    "        plt.plot(steps,losses,label = 'loss')\n",
    "        plt.show()\n",
    "    '''\n",
    "    t+=1\n",
    "dataL = L.data.numpy()\n",
    "dataS = S.data.numpy()\n",
    "dataN = N.data.numpy()\n",
    "data_ = dataL+dataS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T13:10:05.473494Z",
     "start_time": "2019-09-29T13:10:03.967562Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#设置图大小\n",
    "size = 10\n",
    "\n",
    "#让图转起来，每次绘图都清空掉上一次绘制结果\n",
    "import IPython\n",
    "IPython.display.clear_output(wait=True)\n",
    "\n",
    "plt.figure(1,(8,8))\n",
    "\n",
    "plt.scatter(data[:,0],data[:,1],label='origin data')\n",
    "plt.scatter(data_[:,0],data_[:,1],label='restructured data')\n",
    "\n",
    "vals,vecs = np.linalg.eig(np.cov(dataL.T))\n",
    "vecs\n",
    "i=0\n",
    "#绘制两个主成分的方向\n",
    "ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "ev = (ev+dataL.mean(0))\n",
    "plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "i=1\n",
    "ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "ev = (ev+dataL.mean(0))\n",
    "plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "\n",
    "#绘制一下原始数据和重构数据的连线\n",
    "for j in range(len(data)):\n",
    "    plt.plot([data[j,0],data_[j,0]],[data[j,1],data_[j,1]],c='black',linewidth = 0.5)\n",
    "\n",
    "\n",
    "#画一下x轴y轴\n",
    "plt.plot([-size,size],[0,0],c='black')\n",
    "plt.plot([0,0],[-size,size],c='black')\n",
    "plt.xlim(-12.5,12.5)\n",
    "plt.ylim(-12.5,12.5)\n",
    "plt.title('result of PCA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T13:10:10.693670Z",
     "start_time": "2019-09-29T13:10:10.430165Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def spcp(data):\n",
    "    LR = 0.01\n",
    "\n",
    "    L = torch.zeros([m,n],dtype=torch.float ,requires_grad=True)\n",
    "    S = torch.zeros([m,n],dtype=torch.float ,requires_grad=True)\n",
    "    M =  torch.tensor(data,dtype=torch.float ,requires_grad=False)\n",
    "    N = M-L-S\n",
    "    lambda1 = 1/(max(m,n)**0.5)\n",
    "    mu = 1/20 * torch.norm(M,p = 'nuc')\n",
    "\n",
    "    optimizer = torch.optim.Adam([L,S],lr = LR,betas = (0.9,0.99))    \n",
    "\n",
    "    t = 1\n",
    "    steps = []\n",
    "    losses = []\n",
    "    while torch.norm(N) > mu:\n",
    "        steps.append(t)\n",
    "\n",
    "        N = M-L-S\n",
    "        loss = torch.norm(L,p = 'nuc')+lambda1 * torch.norm(S,p =1) + mu * torch.norm(N)\n",
    "        losses.append(loss)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()      #初始化梯度\n",
    "        loss.backward()         #计算梯度\n",
    "        optimizer.step()   \n",
    "        '''\n",
    "        if t%10 == 0:\n",
    "            import IPython\n",
    "            IPython.display.clear_output(wait=True)\n",
    "\n",
    "            plt.plot(steps,losses,label = 'loss')\n",
    "            plt.plot(steps,losses,label = 'loss')\n",
    "            plt.show()\n",
    "        '''\n",
    "        t+=1\n",
    "    dataL = L.data.numpy()\n",
    "    dataS = S.data.numpy()\n",
    "    dataN = N.data.numpy()\n",
    "    return dataL,dataS,dataN\n",
    "dataL,dataS,dataN = spcp(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T13:28:01.966987Z",
     "start_time": "2019-09-29T13:27:28.581703Z"
    }
   },
   "outputs": [],
   "source": [
    "# 观察异常值对spcp的影响\n",
    "for i in range(0,720,10):\n",
    "    import matplotlib.pyplot as plt\n",
    "    #设置图大小\n",
    "    size = 10\n",
    "\n",
    "    #让图转起来，每次绘图都清空掉上一次绘制结果\n",
    "    import IPython\n",
    "    IPython.display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(1,(15,7))\n",
    "    ax1=plt.subplot(121)\n",
    "    ax2=plt.subplot(122)\n",
    "    \n",
    "    \n",
    "    #造数据\n",
    "    np.random.seed(0)\n",
    "    data = np.random.uniform(1,10,(20,2))\n",
    "    data[:,1:] = 0.5*data[:,0:1]+np.random.uniform(-2,2,(20,1))\n",
    "    \n",
    "\n",
    "\n",
    "    #如果我们在数据中加入异常值,定义一个角度放入异常值\n",
    "    i = 2*i/360*np.pi\n",
    "    data_outsider=[np.sin(i)*5*i/(2*np.pi),np.cos(i)*5*i/(2*np.pi)]\n",
    "    data = np.vstack((data,data_outsider))\n",
    "    \n",
    "    \n",
    "    #SPCP\n",
    "    dataL,dataS,dataN = spcp(data)\n",
    "    data_ = dataL+dataS\n",
    "    \n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    plt.sca(ax1)\n",
    "    plt.scatter(data[:,0],data[:,1],label='origin data')\n",
    "    plt.scatter(data_[:,0],data_[:,1],label='restructured data')\n",
    "    plt.scatter(data[-1,0],data[-1,1],label='outsider')\n",
    "    \n",
    "    vals,vecs = np.linalg.eig(np.cov(dataL.T))\n",
    "    vecs\n",
    "    i=0\n",
    "    #绘制两个主成分的方向\n",
    "    ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "    ev = (ev+dataL.mean(0))\n",
    "    plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "    i=1\n",
    "    ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "    ev = (ev+dataL.mean(0))\n",
    "    plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "    #绘制一下原始数据和重构数据的连线\n",
    "    for j in range(len(data)):\n",
    "        plt.plot([data[j,0],data_[j,0]],[data[j,1],data_[j,1]],c='black',linewidth = 0.5)\n",
    "\n",
    "\n",
    "    #画一下x轴y轴\n",
    "    plt.plot([-size,size],[0,0],c='black')\n",
    "    plt.plot([0,0],[-size,size],c='black')\n",
    "    plt.xlim(-12.5,12.5)\n",
    "    plt.ylim(-12.5,12.5)\n",
    "    plt.title('result of spcp')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    #PCA\n",
    "    plt.sca(ax2)\n",
    "    #去中心化\n",
    "    data_normal = data-data.mean(0)\n",
    "    X = data_normal[:,0]\n",
    "    Y = data_normal[:,1]\n",
    "    \n",
    "    #协方差矩阵\n",
    "    C = np.cov(data_normal.T)\n",
    "    \n",
    "    #计算特征值和特征向量\n",
    "    vals, vecs = np.linalg.eig(C)\n",
    "    \n",
    "\n",
    "\n",
    "    #数据在主成分1上的投影坐标是\n",
    "    zcf1 = np.matmul(data_normal,vecs[:,0])\n",
    "    \n",
    "    #只用主成分1重构数据\n",
    "    data_ = np.matmul(zcf1.reshape(len(data),1),vecs[:,0].reshape(1,2))+data.mean(0)\n",
    "\n",
    "    plt.scatter(data[:,0],data[:,1],label='origin data')\n",
    "    plt.scatter(data_[:,0],data_[:,1],label='restructured data')\n",
    "    plt.scatter(data[-1,0],data[-1,1],label='outsider')\n",
    "    \n",
    "    i=0\n",
    "    #绘制两个主成分的方向\n",
    "    ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "    ev = (ev+data.mean(0))\n",
    "    plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "    i=1\n",
    "    ev = np.array([vecs[:,i]*-1,vecs[:,i]])*size\n",
    "    ev = (ev+data.mean(0))\n",
    "    plt.plot(ev[:,0],ev[:,1],label = 'eigen vector '+str(i+1))\n",
    "\n",
    "    #绘制一下原始数据和重构数据的连线\n",
    "    for j in range(len(data)):\n",
    "        plt.plot([data[j,0],data_[j,0]],[data[j,1],data_[j,1]],c='black',linewidth = 0.5)\n",
    "\n",
    "\n",
    "    #画一下x轴y轴\n",
    "    plt.plot([-size,size],[0,0],c='black')\n",
    "    plt.plot([0,0],[-size,size],c='black')\n",
    "    plt.xlim(-12.5,12.5)\n",
    "    plt.ylim(-12.5,12.5)\n",
    "    plt.title('result of PCA')\n",
    "    plt.legend()\n",
    "    #\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-29T13:26:04.297984Z",
     "start_time": "2019-09-29T13:26:04.290966Z"
    }
   },
   "outputs": [],
   "source": [
    "data.mean(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "144px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
