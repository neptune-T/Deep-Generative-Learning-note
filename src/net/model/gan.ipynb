{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage as nd\n",
    "import scipy.io as io\n",
    "import matplotlib\n",
    "\n",
    "import skimage.measure as sk\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.gridspec as gridspec\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "\n",
    "from collections import OrderedDict\n",
    "import binvox_rw as binvox\n",
    "\n",
    "from model import net_G, net_D\n",
    "import params\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "# Example: Setting some hyperparameters and paths (assuming this based on usual practice)\n",
    "params = {\n",
    "    \"batch_size\": 64,              \n",
    "    \"learning_rate\": 0.0002,       \n",
    "    \"epochs\": 100,                 \n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), \n",
    "    \"model_save_path\": \"./models\", \n",
    "    \"data_path\": \"./data\",        \n",
    "    # Other hyperparameters...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "net_G = net_G().to(params[\"device\"])  # 将生成器加载到指定设备\n",
    "net_D = net_D().to(params[\"device\"])  # 将判别器加载到指定设备\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.BCELoss()  # 二分类交叉熵损失，用于判断真假\n",
    "\n",
    "# Define optimizers\n",
    "optimizer_G = optim.Adam(net_G.parameters(), lr=params[\"learning_rate\"])  # Adam优化器用于生成器\n",
    "optimizer_D = optim.Adam(net_D.parameters(), lr=params[\"learning_rate\"])  # Adam优化器用于判别器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = ...  # 加载数据集的逻辑（例如，使用torchvision.datasets等）\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "\n",
    "# Example: ImageFolder\n",
    "# from torchvision import datasets, transforms\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(64),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.5], [0.5])\n",
    "# ])\n",
    "# dataset = datasets.ImageFolder(root=params[\"data_path\"], transform=transform)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=params[\"batch_size\"], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mparams\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;66;03m# 训练判别器\u001b[39;00m\n\u001b[0;32m      4\u001b[0m         optimizer_D\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(params[\"epochs\"]):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # 训练判别器\n",
    "        optimizer_D.zero_grad()\n",
    "        real_imgs = data[0].to(params[\"device\"])\n",
    "        real_labels = torch.ones(real_imgs.size(0), 1).to(params[\"device\"])\n",
    "        fake_labels = torch.zeros(real_imgs.size(0), 1).to(params[\"device\"])\n",
    "        \n",
    "        outputs = net_D(real_imgs)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "        \n",
    "        z = torch.randn(real_imgs.size(0), 100).to(params[\"device\"])  # 随机噪声输入生成器\n",
    "        fake_imgs = net_G(z)\n",
    "        outputs = net_D(fake_imgs.detach())\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "        \n",
    "        optimizer_D.step()\n",
    "\n",
    "        # 训练生成器\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = net_D(fake_imgs)\n",
    "        g_loss = criterion(outputs, real_labels)  # 生成器希望判别器认为假图像为真\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # 打印和记录损失\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Epoch [{epoch}/{params['epochs']}], Step [{i}/{len(dataloader)}], d_loss: {d_loss_real.item() + d_loss_fake.item()}, g_loss: {g_loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
